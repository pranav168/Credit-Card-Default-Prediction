# -*- coding: utf-8 -*-
"""Credit Card Default Prediction Final Capstone Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mb3h6ABEkMZXq-03FAGjYpefOE-xnSNk

# <b><u> Project Title : Predicting whether a customer will default on his/her credit card </u></b>

## <b> Problem Description </b>

### This project is aimed at predicting the case of customers default payments in Taiwan. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. We can use the [K-S chart](https://www.listendata.com/2019/07/KS-Statistics-Python.html) to evaluate which customers will default on their credit card payments

## <b> Data Description </b>

### <b>Attribute Information: </b>

### This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:
* ### X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.
* ### X2: Gender (1 = male; 2 = female).
* ### X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).
* ### X4: Marital status (1 = married; 2 = single; 3 = others).
* ### X5: Age (year).
* ### X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.
* ### X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.
* ### X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.
"""

from google.colab import drive                                                  #Mounting Gdrive
drive.mount('/content/drive')

#Importing all the required Libraries
import numpy as np                                                              # Numpy for enabling scientific computing in Python
import pandas as pd                                                             # Pandas to Deal with the Dataset
import matplotlib.pyplot as plt                                                 #for data visualiztion
import seaborn as sns
from sklearn.metrics import mean_squared_error                                  #for calculation MSE
from sklearn.model_selection import train_test_split                            #for spliting our dataset into train and test
from sklearn.tree import DecisionTreeClassifier                                 #DecisionTreeClassifier Models
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix,classification_report #metrics to calculate our model performance
import warnings                                                                 # Removing all those annoying Warnings
warnings.filterwarnings('ignore')
warnings.simplefilter('ignore')
from xgboost import XGBClassifier                                               #XGBoost Model
from sklearn.model_selection import GridSearchCV                                #for Cross Validation
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, MinMaxScaler,Normalizer,StandardScaler #For data normalization
from sklearn.linear_model import LogisticRegressionCV,LogisticRegression        #Logistic Regression Model
from sklearn.model_selection import cross_validate
from sklearn.ensemble import IsolationForest                                    #for anomaly detection
from scipy import stats                  
from tensorflow import keras                                                    
from keras import Sequential                                                    #NN Model
from keras.layers import Dense                                                  
from sklearn.svm import SVC
!pip install colorama
from colorama import Fore
from imblearn.over_sampling import SMOTE                                        #for creating synthetic data of minority class
pd.set_option("display.max_rows", None, "display.max_columns", None)

df=pd.read_excel('/content/drive/MyDrive/Copy of default of credit card clients.xls',header=1)          #Loading the Dataset
df.head()

df.info()                                                                        #no Nan/null values

df.describe()                                                                   #getting the idea about numerical fields of the data

df.drop('ID',axis=1,inplace=True)                                               #straight away removing ID as it is not at all needed as their is no advantageous relation between our lable(i.e default payment next month) and ID.

df.head()                                                                       #having a peek at working data set

df.columns

column_list=['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',
       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',
       'default payment next month']
count_dataset=pd.DataFrame()
distinct_features=[]                                                                                          #Empty list to know the number of distict features,sum of all these values, and sum of values top 10 comprises
for i in column_list:                                                                                               
  count_dataset[i]= pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).index)      
  count_dataset[f'{i}_count']=pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).values).astype('int')   
  distinct_features.append((len(df[i].value_counts().index),df[i].value_counts().sum(),df[i].value_counts().sort_values(ascending=False).head(10).sum())) 
final_tally=list(zip(column_list,distinct_features))                                                           #Zipping with column_list
col_ref={}  
for i in column_list:
  if i in ['default payment next month']:                                                                    #colur red shows the Dependent Variable('default payment next month')
    col_ref[i]='background-color: red'  
  else:
    col_ref[i]='background-color: blue'                                                                       #colur blue shows the features 
  temp=f'{i}_count'
  col_ref[temp]='background-color: green'                                                                     #colur green shows the count
def Nan_as_black(val):
  if str(val)=='nan':
    color = 'black'
    return 'color: %s' % color
count_dataset=count_dataset.style.apply(lambda x: pd.DataFrame(col_ref, index=count_dataset.index, columns=count_dataset.columns).fillna(''), axis=None).highlight_null('black').applymap(Nan_as_black)
count_dataset

corr = df.corr()                                                                #plotting co-relation chart
plt.figure(figsize=(25,15))
sns.heatmap(corr, annot=True)
plt.show()

"""few features are highly correlated to each other, well settle this multicollinearity later when dealing with models which are not immune to it

also we can see that correlation between our label and features is not that great especially for certain features like bill_amt's, pay_amt's , sex, marriage and age. this is actually a matter of concern!!
"""

df_default=df[df['default payment next month']==1]                              #Making a Dataset only for the defaulters for data visualization purpose

columns = ['SEX','AGE', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2','PAY_3', 'PAY_4', 'PAY_5', 'PAY_6','default payment next month']
fig, axs = plt.subplots(len(columns),3,figsize=(30,40))
count=0
for i in columns:
    sns.distplot(df[i],ax=axs[count,0])                                         #shows the overall distribution 
    sns.distplot(df_default[i],ax=axs[count,0],color='r')                       #shows the distribution of defaulters
    count+=1
count=0
for i in columns:
    sns.countplot(df[i],ax=axs[count,1])
    count+=1
counter=0
for i in columns:
  temp=df.groupby(i)['default payment next month'].count()
  temp2=df_default.groupby(i)['default payment next month'].count() 
  sns.barplot(temp.index,temp.values,ax=axs[counter,2],color='b')               #Blue Colour represents Data for both Defaulters and non-Defaulters
  sns.barplot(temp2.index,temp2.values,color='r',ax=axs[counter,2])             ##Red color represents the Defaulters
  counter+=1

"""Loads of interpretations can be formed by looking at above charts:


1.   Column 1 shows the distributions of all the values in blue and defaulters in red
2.   Column 2 shows the counts of all the values &
3.    Column 3 shows the count plot of Defaulte

Lets do a Anomaly detection now, the most correlated feature with our label is PAY_0 and similar others which actually is quite logical for this prediction and thus we will use this relation to find anomalies. (here anomalies signifies to person who are very punctual but have been defaulter because of certain unavoidable reasons and vice-versa)
"""

minmax = MinMaxScaler(feature_range=(0, 1))
X = minmax.fit_transform(df[['PAY_0', 'PAY_2','PAY_3', 'PAY_4', 'PAY_5', 'PAY_6','default payment next month']])
clf = IsolationForest(n_estimators=100, contamination=0.01, random_state=0)     #Isolation Forest algorithm for anomaly detection
clf.fit(X)

df['multivariate_anomaly_score'] = clf.decision_function(X)                     # predict raw anomaly score
df['multivariate_outlier'] = clf.predict(X)                                     # prediction of a datapoint category outlier or inlier
df2=df

df=df[df.multivariate_outlier==1]                                               #updating data
print(df.shape)  #outliers have been removed
df.drop(['multivariate_anomaly_score','multivariate_outlier'],axis=1,inplace=True)

df_one_hot=pd.DataFrame()

one_hot_entity=['Pay_september','Pay_august','Pay_july','Pay_june','Pay_may','Pay_april']    
column_one_hot=['PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']                # one hot encoding 
count=0
for i in column_one_hot:
  temp_df=pd.get_dummies(df[i], prefix=one_hot_entity[count])
  count+=1
  try:
    df_one_hot=pd.concat([df_one_hot, temp_df], axis=1)
  except:
    df_one_hot=temp_df
df_one_hot.head()

df=pd.concat([df,df_one_hot], axis=1)

df.drop(column_one_hot,axis=1,inplace=True)
df.head()

"""#DecisionTree, RandomForest and XGBoost"""

X = df.drop(["default payment next month"],axis =1 )                            #making Final Datasets
y = df["default payment next month"]

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size =0.2,random_state=0) #train test split

def DecisionTreePrediction(X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,max_depth=3,prediction=False,feature_plot=False,visuals=False): 
  '''
  Apply DecisionTree model on dataset to return the predicted values of test_set
  Takes input :
  For training model:
  X_train: astype numpy_array or pandas.core.frame.DataFrame, 
          contains features of Training set y_train: astype numpy_array, 
          contain lables of Training set
  For testing model performance:
  X_test: astype numpy_array or pandas.core.frame.DataFrame,
          contains features of Test set for which predictions are to be made
  y_test: astype numpy_array or pandas.core.frame.DataFrame,contains lables of 
          Training set for accuracy prediction
  max_depth: astype int, maximum depth of decision tree
  prediction: astype Boolean, if True returns predictions for X_test
  '''
  from sklearn.metrics import accuracy_score, confusion_matrix,classification_report
  model= DecisionTreeClassifier(random_state=0,max_depth=max_depth)              #defining model
  model.fit(X_train,y_train)                                                     #training model
  y_pred_test=model.predict(X_test)                                              #predicting test_dataset
  y_pred_train=model.predict(X_train)
  mse=mean_squared_error(y_test,y_pred_test)                                     #calculating mean-square-error
  accuracy_test=accuracy_score(y_test,y_pred_test)                               #calculating accuracy
  accuracy_train=accuracy_score(y_train,y_pred_train)
  cm=confusion_matrix(y_test,y_pred_test)
  classificationReport=classification_report(y_test,y_pred_test,target_names=['Non-Defaulter', 'Defaulter'])
  if feature_plot==True:                                                                         
      important_Feature=pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)
      plt.figure(figsize=(25,10))
      sns.barplot(important_Feature.index,important_Feature.values)
      plt.xticks(rotation=90)
      print(plt.show)
  if prediction==True:
      print(y_pred_test)
  if visuals==True:
    from sklearn.tree import export_graphviz
    from sklearn import tree
    from IPython.display import SVG
    from graphviz import Source
    from IPython.display import display
    graph = Source(tree.export_graphviz(model, out_file=None
      , feature_names=X_train.columns, class_names=['0', '1'] 
      , filled = True))
    display(SVG(graph.pipe(format='svg')))
  return f'At max_depth ={ max_depth}: MSE = {mse}, Accuracy Score for Train Samples ={round(accuracy_train,4)*100}% and Accuracy Score for Test Samples ={round(accuracy_test,4)*100}% {print(Fore.RED+classificationReport+Fore.BLUE)}'

max_depth=[3,5,7,10,12]                                                         #Checking for Various depths
for i in max_depth:
  print(DecisionTreePrediction(X_train,y_train,X_test,y_test,i,False,))

"""Max Accuracy using Decision Tree is 83.03%"""

DecisionTreePrediction(X_train,y_train,X_test,y_test,5,False,True,True)         #for max depth 3, i am running the model to get some visuals of tree and feature importance chart

"""This Graph is very intrutive, it is clear now that most important feature in  deciding that person in Defaulter or not is the status of his past month credit card bill payment.



"""

model=XGBClassifier()                                                           #XGBoost
n_estimators = [5,10,20,50,100]
max_depth = [3,4,5,6,7]
param_grid = dict(max_depth=max_depth,n_estimators=n_estimators)                                          
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)
grid_search = GridSearchCV(model, param_grid, scoring="neg_log_loss", n_jobs=-1, cv=kfold)
grid_result = grid_search.fit(X_train, y_train)   
# summarize results
print(Fore.RED+"Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_)+Fore.BLUE)
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
	print("%f (%f) with: %r" % (mean, stdev, param))

scores = np.array(means).reshape(len(max_depth), len(n_estimators))
for i, value in enumerate(max_depth):
    plt.plot(n_estimators, scores[i], label='depth: ' + str(value))
plt.legend()
plt.xlabel('n_estimators')
plt.ylabel('Log Loss')
plt.savefig('n_estimators_vs_max_depth.png')

model2=XGBClassifier(max_depth=4,n_estimators=100)
model2.fit(X_train,y_train)
y_pred_test2=model2.predict(X_test)                                              
y_pred_train2=model2.predict(X_train)
y_pred_test_prob=model2.predict_proba(X_test)                                   # will be used for KS Chart Calculation
mse2=mean_squared_error(y_test,y_pred_test2)                                    
accuracy_test2=accuracy_score(y_test,y_pred_test2)                              
accuracy_train2=accuracy_score(y_train,y_pred_train2)
print(Fore.BLUE+f'MSE = {mse2}, Accuracy Score for Train Samples ={round(accuracy_train2,3)} and Accuracy Score for Test Samples ={round(accuracy_test2,3)}')

important_Feature=pd.Series(model2.feature_importances_, X_train.columns).sort_values(ascending=False)
plt.figure(figsize=(25,10))
sns.barplot(important_Feature.index,important_Feature.values)
plt.xticks(rotation=90)
plt.show

labels = ['Non-Defaulter', 'Defaulter']
cm_test = confusion_matrix(y_test, y_pred_test2)
ax= plt.subplot()
sns.heatmap(cm_test, annot=True, ax = ax) 
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)

print(Fore.RED+classification_report(y_test,y_pred_test2,target_names=['Non-Defaulter', 'Defaulter']))

model=RandomForestClassifier(n_estimators=100)
model.fit(X_train,y_train)
y_pred_test=model.predict(X_test)
y_pred_train=model.predict(X_train)
accuracy_score_test=accuracy_score(y_test,y_pred_test)
accuracy_score_train=accuracy_score(y_train,y_pred_train)
mse=mean_squared_error(y_test,y_pred_test) 
print(f'MSE = {mse}, Accuracy Score for Train Samples ={accuracy_score_train} and Accuracy Score for Test Samples ={accuracy_score_test} for Random Forest Classifier')
print(classification_report(y_test,y_pred_test))
labels = ['Non-Defaulter', 'Defaulter']
cm_test = confusion_matrix(y_test, y_pred_test)
print(cm_test)
ax= plt.subplot()
sns.heatmap(cm_test, annot=True, ax = ax) 
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)
plt.show()
important_Feature=pd.Series(model.feature_importances_, X_train.columns).sort_values(ascending=False)
plt.figure(figsize=(25,10))
sns.barplot(important_Feature.index,important_Feature.values)
plt.xticks(rotation=90)
plt.show

"""Thus using XGBoost Best result i could get is MSE:

*    MSE = 0.16818181818181818, Accuracy Score for Train Samples =0.829 and Accuracy Score for Test Samples =0.832
*  but the condition of F1 score for Default prediction is really bad due to class imbalance lets try to solve it.


#Trying Oversampling Technique (SMOTE)

"""

oversample = SMOTE() #usnig oversampling technique to create synthetic data and deal with class inbalance
X, y = oversample.fit_resample(X, y)

X

sns.countplot(y)

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size =0.2,random_state=0) #train test split

DecisionTreePrediction()

model=XGBClassifier() #XGBoost
n_estimators = [150,200,300]
max_depth = [10,12,14]
param_grid = dict(max_depth=max_depth,n_estimators=n_estimators)                                          
kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=7)
grid_search = GridSearchCV(model, param_grid, scoring="neg_log_loss", n_jobs=-1, cv=kfold)
grid_result = grid_search.fit(X_train, y_train)   
# summarize results
print(Fore.RED+"Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_)+Fore.BLUE)
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
	print("%f (%f) with: %r" % (mean, stdev, param))

scores = np.array(means).reshape(len(max_depth), len(n_estimators))
for i, value in enumerate(max_depth):
    plt.plot(n_estimators, scores[i], label='depth: ' + str(value))
plt.legend()
plt.xlabel('n_estimators')
plt.ylabel('Log Loss')
plt.savefig('n_estimators_vs_max_depth.png')

model2=XGBClassifier(max_depth=10,n_estimators=150)
model2.fit(X_train,y_train)
y_pred_test2=model2.predict(X_test)                                              
y_pred_train2=model2.predict(X_train)
y_pred_test_prob=model2.predict_proba(X_test)                                   # will be used for KS Chart Calculation
mse2=mean_squared_error(y_test,y_pred_test2)                                    
accuracy_test2=accuracy_score(y_test,y_pred_test2)                              
accuracy_train2=accuracy_score(y_train,y_pred_train2)
print(Fore.BLUE+f'MSE = {mse2}, Accuracy Score for Train Samples ={round(accuracy_train2,3)} and Accuracy Score for Test Samples ={round(accuracy_test2,3)}')

labels = ['Non-Defaulter', 'Defaulter']
cm_test = confusion_matrix(y_test, y_pred_test2)
print(cm_test)
ax= plt.subplot()
sns.heatmap(cm_test, annot=True, ax = ax) 
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)
plt.show()

print(Fore.RED+classification_report(y_test,y_pred_test2,target_names=['Non-Defaulter', 'Defaulter']))

model=RandomForestClassifier(n_estimators=100)
model.fit(X_train,y_train)
y_pred_test_rf=model.predict(X_test)
y_pred_train=model.predict(X_train)
accuracy_score_test=accuracy_score(y_test,y_pred_test_rf)
accuracy_score_train=accuracy_score(y_train,y_pred_train)
y_pred_test_prob_rf=model2.predict_proba(X_test)    
mse=mean_squared_error(y_test,y_pred_test_rf) 
print(f'MSE = {mse}, Accuracy Score for Train Samples ={accuracy_score_train} and Accuracy Score for Test Samples ={accuracy_score_test} for Random Forest Classifier')
print(classification_report(y_test,y_pred_test_rf))
labels = ['Non-Defaulter', 'Defaulter']
cm_test = confusion_matrix(y_test, y_pred_test_rf)
print(cm_test)
ax= plt.subplot()
sns.heatmap(cm_test, annot=True, ax = ax) 
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)
plt.show()

"""**bold text**

XGBoost and Random Forest provides the Best Chances of Predicting Defaulters so far with 88% accuracy,we will now process our data for other models and mainly for logistic regression.

#Now we'll be using Logistic Regression & SVM thus we will have to process our data further
"""

df['Total_BILL_AMT']=df.BILL_AMT1+df.BILL_AMT2+df.BILL_AMT3+df.BILL_AMT4+df.BILL_AMT5+df.BILL_AMT6              #adding all bill amount as they are highly corelated
df.drop(df[['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']], axis=1,inplace=True)

df.head()

one_hot_entity2=['SEX','EDUCATION','MARRIAGE','AGE']
column_one_hot=['SEX','EDUCATION','MARRIAGE','AGE']
count=0
for i in column_one_hot:
  temp_df2=pd.get_dummies(df[i], prefix=one_hot_entity2[count])
  count+=1
  try:
    df_one_hot2=pd.concat([df_one_hot2, temp_df2], axis=1)
  except:
    df_one_hot2=temp_df2
df_one_hot2.head()

df=pd.concat([df,df_one_hot2], axis=1)

X = df.drop(["default payment next month"],axis =1 )                                                            #making Final Datasets
y = df["default payment next month"]
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size =0.2,random_state=0)                            #getting new values

scaler=MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)

model3 = {LogisticRegression(fit_intercept=True, max_iter=10000)          : 'Logistic Model',
          Sequential([
                      Dense(32,input_dim=123,activation='relu'),   
                      Dense(32,activation='relu'),   
                      Dense(64,activation='relu'),       
                      Dense(2,activation='softmax')
          ])                                                              : 'Neural Network',
          SVC(kernel='linear')                                            : 'SVM'
          }
count=0
for model,name in model3.items():
  if count==1:
    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])     #implementation for neural network is a bit different and thus i have created this conditional statement
    model.fit(X_train, y_train,epochs=10,batch_size=16,validation_split=0.2)
    train_class_preds = model.predict(X_train)
    test_class_preds = model.predict(X_test)
    train_class_preds = np.argmax(train_class_preds,axis=-1)
    test_class_preds = np.argmax(test_class_preds,axis=-1)
  else:
    model.fit(X_train, y_train)
    train_class_preds = model.predict(X_train)
    test_class_preds = model.predict(X_test)
  try:
    test_class_prob=model.predict_proba(X_test)
  except:
    pass
  train_accuracy = accuracy_score(train_class_preds,y_train)
  test_accuracy = accuracy_score(test_class_preds,y_test)
  if count==0:
    scoring = ['accuracy']
    scores = cross_validate(model,X_train, y_train, scoring = scoring, cv = 5, return_train_score=True,verbose = 5)
 
  
  
  print(Fore.BLUE +f"The accuracy on train data is {round(train_accuracy*100,2)}% and The accuracy on test data is {round(test_accuracy*100,2)}% for model {name}")
  labels = ['Non-Defaulter', 'Defaulter']
  cm_test = confusion_matrix(y_test, test_class_preds)
  fig, ax= plt.subplots(figsize=(20,5))
  sns.heatmap(cm_test, annot=True, ax = ax) 
  ax.set_xlabel('Predicted labels')
  ax.set_ylabel('True labels')
  ax.set_title('Confusion Matrix')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)

  plt.show()
  print(Fore.RED+classification_report(y_test,test_class_preds,target_names=['Non-Defaulter', 'Defaulter'])+Fore.YELLOW)  
  count+=1

"""Again Recall is very low and thus i will be using the SMOTE on this transformed dataset aswell"""

oversample = SMOTE()                                                                              #usnig oversampling technique to create synthetic data and deal with class inbalance
X, y = oversample.fit_resample(X, y)
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size =0.2,random_state=0)
'''------------------------------------------------------------------------------------------------------------Code Written Below is similar to what i have done above-------------------------------------------------------------'''
scaler=MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)
model3 = {LogisticRegression(fit_intercept=True, max_iter=10000)          : 'Logistic Model',
          Sequential([
                      Dense(16,input_dim=123,activation='relu'),    
                      Dense(32,activation='relu'),  
                      Dense(64,activation='relu'),
                      Dense(128,activation='relu'),
                      Dense(2,activation='softmax')
          ])                                                              : 'Neural Network',
          SVC(kernel='linear')                                            : 'SVM'
          }
count=0
for model,name in model3.items():
  if count==1:
    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])    #implementation for neural network is a bit different and thus i have created this conditional statement
    model.fit(X_train, y_train,epochs=10,batch_size=16,validation_split=0.1)
    train_class_preds = model.predict(X_train)
    test_class_preds = model.predict(X_test)
    train_class_preds = np.argmax(train_class_preds,axis=-1)
    test_class_preds = np.argmax(test_class_preds,axis=-1)
  else:
    model.fit(X_train, y_train)
    train_class_preds = model.predict(X_train)
    test_class_preds = model.predict(X_test)
  if count==0:                                                                                     #Saving info of linear model for further analysis
    test_class_prob_linear=model.predict_proba(X_test)
    train_class_preds_linear = model.predict(X_train)
    test_class_preds_linear = model.predict(X_test)
  train_accuracy = accuracy_score(train_class_preds,y_train)
  test_accuracy = accuracy_score(test_class_preds,y_test)
  if count==0:
    scoring = ['accuracy']
    scores = cross_validate(model,X_train, y_train, scoring = scoring, cv = 5, return_train_score=True,verbose = 5)
 
  
  from colorama import Fore
  print(Fore.BLUE +f"The accuracy on train data is {round(train_accuracy*100,2)}% and The accuracy on test data is {round(test_accuracy*100,2)}% for model {name}")
  labels = ['Non-Defaulter', 'Defaulter']
  cm_test = confusion_matrix(y_test, test_class_preds)
  fig, ax= plt.subplots(figsize=(20,5))
  sns.heatmap(cm_test, annot=True, ax = ax) 
  ax.set_xlabel('Predicted labels')
  ax.set_ylabel('True labels')
  ax.set_title('Confusion Matrix')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)

  plt.show()
  print(Fore.RED+classification_report(y_test,test_class_preds,target_names=['Non-Defaulter', 'Defaulter'])+Fore.YELLOW)
  
  count+=1

sns.distplot(x=y_test)
sns.distplot(x=test_class_preds_linear,color='red')

"""Linear Regression, Neural Network and SVM performed Equally Good with arounf 89% precision and recall, and thus accuracy as well.

#Ks_chart
"""

max_p=[]
for i in range(len(test_class_prob_linear)):                        
  max_p.append(max(test_class_prob_linear[i]))
ks_chart=pd.DataFrame(max_p,columns=['p'])
ks_chart['y']=test_class_preds_linear

ks_chart.head()

def ks(data=None,target=None, prob=None):
    data['target0'] = 1 - data[target]
    data['bucket'] = pd.qcut(data[prob], 10)
    grouped = data.groupby('bucket', as_index = False)
    kstable = pd.DataFrame()
    kstable['min_prob'] = grouped.min()[prob]
    kstable['max_prob'] = grouped.max()[prob]
    kstable['events']   = grouped.sum()[target]
    kstable['nonevents'] = grouped.sum()['target0']
    kstable = kstable.sort_values(by="min_prob", ascending=False).reset_index(drop = True)
    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)
    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)
    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()
    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()
    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100

    #Formating
    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)
    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)
    kstable.index = range(1,11)
    kstable.index.rename('Decile', inplace=True)
    pd.set_option('display.max_columns', 9)
    print(kstable)
    
    #Display KS
    print(Fore.RED+"KS is " + str(max(kstable['KS']))+"%"+ " at decile " + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))
    return(kstable)

mydf = ks(data=ks_chart,target="y", prob="p")

"""Really Great!! we can definately differentiate between the both classes our Final Model will be the most Linear Regression Model as it surpasses every other model despite to being the most basic model"""